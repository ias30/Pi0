#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–ç‰ˆHDF5å­˜å‚¨ç®¡ç†å™¨
è§£å†³0.5Hz â†’ 30Hzæ€§èƒ½ç“¶é¢ˆï¼ŒåŸºäºDiffusion Policyä¼˜åŒ–æ€è·¯
æ›´æ–°ä¸ºæ–°çš„ä¸‰ç›¸æœºæ•°æ®ç»“æ„
"""

import os
import h5py
import numpy as np
import threading
import time
import queue
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
from time_sync import get_timestamp, get_timestamp_ms


class OptimizedHDF5Storage:
    """ä¼˜åŒ–ç‰ˆHDF5å­˜å‚¨ç®¡ç†å™¨ - é«˜æ€§èƒ½æ•°æ®é‡‡é›†"""

    def __init__(self, base_dir: str = "data_collection_episodes"):
        """
        åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆHDF5å­˜å‚¨ç®¡ç†å™¨

        Args:
            base_dir: æ•°æ®å­˜å‚¨åŸºç¡€ç›®å½•
        """
        self.base_dir = base_dir
        self.current_file: Optional[h5py.File] = None
        self.current_filename: Optional[str] = None
        self.current_episode_start_time: Optional[float] = None
        self.write_lock = threading.Lock()
        self.is_recording = False
        
        # âš¡ æ€§èƒ½ä¼˜åŒ–å‚æ•°
        self.estimated_duration = 180  # é¢„ä¼°æœ€å¤§å½•åˆ¶æ—¶é•¿(ç§’)
        self.target_hz = 30 # ç›®æ ‡é‡‡é›†é¢‘ç‡
        self.estimated_samples = int(self.estimated_duration * self.target_hz * 1.2) # 20%ä½™é‡

        # é¢„åˆ†é…ç©ºé—´è¿½è¸ª
        self.allocated_size: int = 0
        self.current_index: int = 0
        
        # flushä¼˜åŒ–
        self.write_count = 0
        self.flush_interval = 100  # æ¯100æ¬¡å†™å…¥flushä¸€æ¬¡

        # ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
        os.makedirs(self.base_dir, exist_ok=True)
        print(f"ğŸš€ ä¼˜åŒ–ç‰ˆHDF5å­˜å‚¨ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼Œå­˜å‚¨ç›®å½•: {self.base_dir}")

    def start_episode(self, device_mapping: Optional[Dict[str, Any]] = None) -> str:
        """
        å¼€å§‹æ–°çš„Episodeå½•åˆ¶

        Args:
            device_mapping: è®¾å¤‡æ˜ å°„é…ç½®ä¿¡æ¯ï¼ˆå°†è®°å½•åˆ°metadataï¼‰

        Returns:
            æ–°åˆ›å»ºçš„æ–‡ä»¶è·¯å¾„
        """
        with self.write_lock:
            if self.is_recording:
                print("è­¦å‘Šï¼šå·²åœ¨å½•åˆ¶ä¸­ï¼Œå…ˆåœæ­¢å½“å‰Episode")
                self.stop_episode()

            timestamp = datetime.now()
            filename = timestamp.strftime("%Y%m%d_%H%M%S_episode.h5")
            filepath = os.path.join(self.base_dir, filename)

            try:
                self.current_file = h5py.File(filepath, 'w',
                                            rdcc_nbytes=1024*1024*64,
                                            rdcc_nslots=521)
                self.current_filename = filepath
                self.current_episode_start_time = get_timestamp()
                self.is_recording = True

                self.allocated_size = self.estimated_samples
                self.current_index = 0
                self.write_count = 0

                self._write_metadata(device_mapping)
                self._preallocate_datasets()

                print(f"âœ… å¼€å§‹æ–°Episodeå½•åˆ¶: {filepath}")
                print(f"ğŸ“Š é¢„åˆ†é…ç©ºé—´: {self.allocated_size} observations")
                return filepath

            except Exception as e:
                self.current_file = None
                self.current_filename = None
                self.is_recording = False
                error_msg = f"åˆ›å»ºHDF5æ–‡ä»¶å¤±è´¥: {e}"
                print(error_msg)
                raise RuntimeError(error_msg)

    def _preallocate_datasets(self):
        """âš¡ é¢„åˆ†é…æ•°æ®é›†ç©ºé—´ï¼ˆæ–°ä¸‰ç›¸æœºç»“æ„ï¼‰"""
        if self.current_file is None:
            return

        print("ğŸ”§ é¢„åˆ†é…æ•°æ®é›†ç©ºé—´...")
        obs_group = self.current_file.create_group('observations')
        
        # Global Timestamps
        obs_group.create_dataset('global_timestamps', (self.allocated_size,), dtype='f8', chunks=True)

        # Cameras - æ–°ç»“æ„ï¼š1ä¸ªRealSense + 2ä¸ªWristç›¸æœº
        cam_group = obs_group.create_group('cameras')
        
        # camera_high (RealSense with depth)
        cam_high = cam_group.create_group('camera_high')
        cam_high.create_dataset('color', (self.allocated_size, 480, 640, 3), dtype='uint8', chunks=(1, 480, 640, 3))
        cam_high.create_dataset('depth', (self.allocated_size, 480, 640), dtype='uint16', chunks=(1, 480, 640))
        cam_high.create_dataset('local_timestamps', (self.allocated_size,), dtype='f8', chunks=True)
        
        # camera_left_wrist (RGB only)
        cam_left = cam_group.create_group('camera_left_wrist')
        cam_left.create_dataset('color', (self.allocated_size, 480, 640, 3), dtype='uint8', chunks=(1, 480, 640, 3))
        cam_left.create_dataset('local_timestamps', (self.allocated_size,), dtype='f8', chunks=True)
        
        # camera_right_wrist (RGB only)
        cam_right = cam_group.create_group('camera_right_wrist')
        cam_right.create_dataset('color', (self.allocated_size, 480, 640, 3), dtype='uint8', chunks=(1, 480, 640, 3))
        cam_right.create_dataset('local_timestamps', (self.allocated_size,), dtype='f8', chunks=True)

        # Arms
        arm_group = obs_group.create_group('arms')
        for arm_id in ['left_arm', 'right_arm']:
            sub_group = arm_group.create_group(arm_id)
            sub_group.create_dataset('joint_positions', (self.allocated_size, 6), dtype='f8', chunks=(128, 6))
            sub_group.create_dataset('end_effector_poses', (self.allocated_size, 6), dtype='f8', chunks=(128, 6))
            sub_group.create_dataset('local_timestamps', (self.allocated_size,), dtype='f8', chunks=True)

        # Motors
        motor_group = obs_group.create_group('motors')
        for motor_id in ['left_motors', 'right_motors']:
            sub_group = motor_group.create_group(motor_id)
            sub_group.create_dataset('positions', (self.allocated_size, 4), dtype='i4', chunks=(128, 4))
            sub_group.create_dataset('states', (self.allocated_size, 4), dtype='i4', chunks=(128, 4))
            sub_group.create_dataset('local_timestamps', (self.allocated_size,), dtype='f8', chunks=True)

    def stop_episode(self) -> Optional[str]:
        """
        åœæ­¢å½“å‰Episodeå½•åˆ¶
        """
        with self.write_lock:
            if not self.is_recording or self.current_file is None:
                print("å½“å‰æ²¡æœ‰è¿›è¡Œå½•åˆ¶")
                return None
            
            try:
                self._trim_datasets_to_actual_size()
                self._update_final_metadata()
                
                self.current_file.flush()
                self.current_file.close()
                completed_file = self.current_filename
                
                print(f"âœ… Episodeå½•åˆ¶å®Œæˆ: {completed_file}")
                print(f"ğŸ“Š å®é™…æ•°æ®ç»Ÿè®¡: {self.current_index} observations")
                
                self.current_file = None
                self.current_filename = None
                self.current_episode_start_time = None
                self.is_recording = False
                
                return completed_file
                
            except Exception as e:
                error_msg = f"åœæ­¢Episodeå½•åˆ¶æ—¶å‡ºé”™: {e}"
                print(error_msg)
                
                self.current_file = None
                self.current_filename = None
                self.current_episode_start_time = None
                self.is_recording = False
                
                return None

    def _trim_datasets_to_actual_size(self):
        """âš¡ è°ƒæ•´æ•°æ®é›†å¤§å°åˆ°å®é™…ä½¿ç”¨å¤§å°"""
        if self.current_file is None:
            return
        
        actual_size = self.current_index
        if actual_size > 0 and actual_size < self.allocated_size:
            obs_group = self.current_file['observations']
            
            # Recursively resize all datasets
            def resize_datasets(group):
                for key, value in group.items():
                    if isinstance(value, h5py.Dataset):
                        value.resize(actual_size, axis=0)
                    elif isinstance(value, h5py.Group):
                        resize_datasets(value)

            resize_datasets(obs_group)

    def write_observation(self, observation: Dict[str, Any]):
        """
        å†™å…¥ä¸€ä¸ªå®Œæ•´çš„observationæ•°æ®åŒ…ï¼ˆæ–°ä¸‰ç›¸æœºç»“æ„ï¼‰
        """
        if not self.is_recording or self.current_file is None:
            return
        
        with self.write_lock:
            try:
                idx = self.current_index
                if idx >= self.allocated_size:
                    print(f"âš ï¸  Observation ç©ºé—´ä¸è¶³ï¼Œè‡ªåŠ¨æ‰©å±•...")
                    self._expand_datasets()

                obs_group = self.current_file['observations']

                # Global Timestamps
                obs_group['global_timestamps'][idx] = observation['global_timestamp']

                # Cameras - æ–°ç»“æ„
                cameras = observation['cameras']
                
                # camera_high (with depth)
                if 'camera_high' in cameras:
                    cam_data = cameras['camera_high']
                    cam_group = obs_group['cameras']['camera_high']
                    cam_group['color'][idx] = cam_data['color']
                    cam_group['depth'][idx] = cam_data['depth']
                    cam_group['local_timestamps'][idx] = cam_data['local_timestamp']
                
                # camera_left_wrist (RGB only)
                if 'camera_left_wrist' in cameras:
                    cam_data = cameras['camera_left_wrist']
                    cam_group = obs_group['cameras']['camera_left_wrist']
                    cam_group['color'][idx] = cam_data['color']
                    cam_group['local_timestamps'][idx] = cam_data['local_timestamp']
                
                # camera_right_wrist (RGB only)
                if 'camera_right_wrist' in cameras:
                    cam_data = cameras['camera_right_wrist']
                    cam_group = obs_group['cameras']['camera_right_wrist']
                    cam_group['color'][idx] = cam_data['color']
                    cam_group['local_timestamps'][idx] = cam_data['local_timestamp']

                # Arms
                for arm_id in ['left_arm', 'right_arm']:
                    arm_data = observation['arms'][arm_id]
                    arm_group = obs_group['arms'][arm_id]
                    arm_group['joint_positions'][idx] = arm_data['joint_positions']
                    arm_group['end_effector_poses'][idx] = arm_data['end_effector_poses']
                    arm_group['local_timestamps'][idx] = arm_data['local_timestamp']

                # Motors
                for motor_id in ['left_motors', 'right_motors']:
                    motor_data = observation['motors'][motor_id]
                    motor_group = obs_group['motors'][motor_id]
                    motor_group['positions'][idx] = motor_data['positions']
                    motor_group['states'][idx] = motor_data['states']
                    motor_group['local_timestamps'][idx] = motor_data['local_timestamp']
                
                self.current_index += 1
                self._conditional_flush()
            
            except Exception as e:
                error_msg = f"å†™å…¥observationæ•°æ®æ—¶å‡ºé”™: {e}"
                print(error_msg)

    def _expand_datasets(self):
        """æ‰©å±•æ‰€æœ‰æ•°æ®é›†ç©ºé—´"""
        new_size = int(self.allocated_size * 1.5)
        
        obs_group = self.current_file['observations']
        
        def expand_recursive(group):
            for key, value in group.items():
                if isinstance(value, h5py.Dataset):
                    value.resize(new_size, axis=0)
                elif isinstance(value, h5py.Group):
                    expand_recursive(value)
                    
        expand_recursive(obs_group)
        self.allocated_size = new_size
        print(f"ğŸ”§ æ•°æ®é›†ç©ºé—´å·²æ‰©å±•è‡³ {new_size}")

    def _conditional_flush(self):
        """âš¡ æ¡ä»¶æ€§flush - å‡å°‘ç£ç›˜I/O"""
        self.write_count += 1
        if self.write_count % self.flush_interval == 0:
            self.current_file.flush()

    def delete_last_episode(self) -> bool:
        """
        åˆ é™¤æœ€è¿‘çš„Episodeæ–‡ä»¶
        """
        try:
            episode_files = [f for f in os.listdir(self.base_dir) if f.endswith('_episode.h5')]
            if not episode_files:
                print("æ²¡æœ‰æ‰¾åˆ°Episodeæ–‡ä»¶å¯åˆ é™¤")
                return False
            
            episode_files.sort(reverse=True)
            latest_file = os.path.join(self.base_dir, episode_files[0])
            
            os.remove(latest_file)
            print(f"å·²åˆ é™¤æœ€è¿‘çš„Episodeæ–‡ä»¶: {latest_file}")
            return True
            
        except Exception as e:
            print(f"åˆ é™¤Episodeæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False

    def log_error(self, error_message: str):
        """è®°å½•é”™è¯¯ä¿¡æ¯ï¼ˆä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼Œä½†ç°åœ¨é”™è¯¯æ—¥å¿—å­˜å‚¨åœ¨metadataä¸­ï¼‰"""
        print(f"é”™è¯¯è®°å½•: {error_message}")

    def _write_metadata(self, device_mapping: Optional[Dict[str, Any]] = None):
        """å†™å…¥åˆå§‹å…ƒæ•°æ®
        
        Args:
            device_mapping: è®¾å¤‡æ˜ å°„é…ç½®ä¿¡æ¯
        """
        if self.current_file is None: return
        metadata = self.current_file.create_group('metadata')
        metadata.attrs['episode_start_time'] = self.current_episode_start_time
        metadata.attrs['creation_timestamp'] = get_timestamp_ms()
        metadata.attrs['version'] = '4.0_triple_camera'
        
        # è®°å½•è®¾å¤‡æ˜ å°„é…ç½®
        if device_mapping:
            metadata.attrs['swap_arms'] = device_mapping.get('swap_arms', False)
            metadata.attrs['device_mapping_description'] = device_mapping.get('description', '')
            # è®°å½•ç‰©ç†è®¾å¤‡IPï¼ˆç”¨äºè¿½æº¯ï¼‰
            if 'left_device_ip' in device_mapping:
                metadata.attrs['physical_left_device_ip'] = device_mapping['left_device_ip']
            if 'right_device_ip' in device_mapping:
                metadata.attrs['physical_right_device_ip'] = device_mapping['right_device_ip']

    def _update_final_metadata(self):
        """æ›´æ–°æœ€ç»ˆå…ƒæ•°æ®"""
        if self.current_file is None: return
        metadata = self.current_file['metadata']
        end_time = get_timestamp()
        metadata.attrs['episode_end_time'] = end_time
        metadata.attrs['episode_duration'] = end_time - self.current_episode_start_time
        metadata.attrs['observation_count'] = self.current_index

    def get_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰çŠ¶æ€"""
        return {
            'is_recording': self.is_recording,
            'current_file': self.current_filename,
            'observation_count': self.current_index,
            'allocated_size': self.allocated_size,
        }

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.is_recording:
            self.stop_episode()
        print("âœ… ä¼˜åŒ–ç‰ˆHDF5å­˜å‚¨ç®¡ç†å™¨å·²æ¸…ç†")

HDF5Storage = OptimizedHDF5Storage
